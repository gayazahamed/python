{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a347492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in c:\\users\\adil\\appdata\\roaming\\python\\python39\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\adil\\appdata\\roaming\\python\\python39\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d3cc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyspark\n"
     ]
    }
   ],
   "source": [
    "print('Pyspark');\n",
    "import pyspark\n",
    "#pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4ebdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PySpark 3.5.1 version is running...\n",
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "| Krish|  30|         5| 10000|\n",
      "|   Sid|  25|         9| 50000|\n",
      "|  Mary|  41|        16| 75000|\n",
      "|Mahesh|NULL|        16| 90000|\n",
      "|   Sam|  32|      NULL| 70000|\n",
      "|  Miss|  29|        12|  NULL|\n",
      "|      |NULL|      NULL|  NULL|\n",
      "|   pan|NULL|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .appName('BigData-ETL.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "print(f'The PySpark {spark.version} version is running...')\n",
    "\n",
    "path = ['C:/Gayaz/python/PySpark/test.csv']\n",
    " \n",
    "df = spark.read.csv(path, sep=',', #sep='\\t' tab\n",
    "                       inferSchema=True, header=True)  #inferSchema=true if this not there all feilds are strings\n",
    "spark.read.option('header','true')\n",
    "# df1 = files.toPandas()\n",
    "# display(df1.head())\n",
    "# display(df1.tail())\n",
    "df.show();\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3f347b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BigData-ETL.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x241b8228160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5851e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "613966d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "type(df)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede47d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Column<'Age[mean]'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean as mean_, std as std_\n",
    "ff = df.select('Age')\n",
    "ff\n",
    "print(type(ff))\n",
    "mean = ff[0]['mean']\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "117de51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d49fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------------+------------------+\n",
      "|summary| Name|             Age|        Experience|\n",
      "+-------+-----+----------------+------------------+\n",
      "|  count|    3|               3|                 3|\n",
      "|   mean| NULL|            32.0| 6.666666666666667|\n",
      "| stddev| NULL|8.18535277187245|2.0816659994661326|\n",
      "|    min|Krish|              25|                 5|\n",
      "|    max|  Sid|              41|                 9|\n",
      "+-------+-----+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a16e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+--------------+\n",
      "| Name|Age|Experience|Experience + 2|\n",
      "+-----+---+----------+--------------+\n",
      "|Krish| 30|         5|             7|\n",
      "|  Sid| 25|         9|            11|\n",
      "| Mary| 41|         6|             8|\n",
      "+-----+---+----------+--------------+\n",
      "\n",
      "+-----+----------+--------------+\n",
      "| Name|Experience|Experience + 2|\n",
      "+-----+----------+--------------+\n",
      "|Krish|         5|             7|\n",
      "|  Sid|         9|            11|\n",
      "| Mary|         6|             8|\n",
      "+-----+----------+--------------+\n",
      "\n",
      "+--------+---+----------+\n",
      "|New Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|   Krish| 30|         5|\n",
      "|     Sid| 25|         9|\n",
      "|    Mary| 41|         6|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add column\n",
    "dfnew = df.withColumn(\"Experience + 2\",df['Experience']+2)\n",
    "dfnew.show()\n",
    "#drop column\n",
    "dfnew.drop('Age').show()\n",
    "\n",
    "#rename\n",
    "df.withColumnRenamed('Name','New Name').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7db7a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krish', Age=30, Experience=5)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656ef993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "| Name|Age|Experience|\n",
      "+-----+---+----------+\n",
      "|Krish| 30|         5|\n",
      "|  Sid| 25|         9|\n",
      "| Mary| 41|         6|\n",
      "+-----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72db21ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| Name|Experience|\n",
      "+-----+----------+\n",
      "|Krish|         5|\n",
      "|  Sid|         9|\n",
      "| Mary|         6|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newf = df.select('Name','Experience')\n",
    "type(newf)\n",
    "\n",
    "newf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13bcdb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa39e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------------+------------------+\n",
      "|summary| Name|             Age|        Experience|\n",
      "+-------+-----+----------------+------------------+\n",
      "|  count|    3|               3|                 3|\n",
      "|   mean| NULL|            32.0| 6.666666666666667|\n",
      "| stddev| NULL|8.18535277187245|2.0816659994661326|\n",
      "|    min|Krish|              25|                 5|\n",
      "|    max|  Sid|              41|                 9|\n",
      "+-------+-----+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f39af2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Krish| 30|         5|  1000|\n",
      "|  Sid| 25|         9|  5000|\n",
      "| Mary| 41|        16|  7500|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop null\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a350816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "| Krish|  30|         5|  1000|\n",
      "|   Sid|  25|         9|  5000|\n",
      "|  Mary|  41|        16|  7500|\n",
      "|Mahesh|NULL|        16|  9000|\n",
      "|   Sam|  32|      NULL| 70000|\n",
      "|  Miss|  29|        12|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#threshold  three nulls\n",
    "df.na.drop(how=\"any\", thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8d4c771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Krish| 30|         5|  1000|\n",
      "|  Sid| 25|         9|  5000|\n",
      "| Mary| 41|        16|  7500|\n",
      "|  Sam| 32|      NULL| 70000|\n",
      "| Miss| 29|        12|  NULL|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how=\"any\", subset=['Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d772992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "| Krish|  30|         5|  1000|\n",
      "|   Sid|  25|         9|  5000|\n",
      "|  Mary|  41|        16|  7500|\n",
      "|Mahesh|NULL|        16|  9000|\n",
      "|   Sam|  32|     12345| 70000|\n",
      "|  Miss|  29|        12|  NULL|\n",
      "|      |NULL|     12345|  NULL|\n",
      "|   pan|NULL|     12345|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fill check the type of the values\n",
    "\n",
    "df.na.fill(12345,['Experience']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8181818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "| Krish|  30|         5|  1000|         30|                 5|          1000|\n",
      "|   Sid|  25|         9|  5000|         25|                 9|          5000|\n",
      "|  Mary|  41|        16|  7500|         41|                16|          7500|\n",
      "|Mahesh|NULL|        16|  9000|         31|                16|          9000|\n",
      "|   Sam|  32|      NULL| 70000|         32|                11|         70000|\n",
      "|  Miss|  29|        12|  NULL|         29|                12|         18500|\n",
      "|      |NULL|      NULL|  NULL|         31|                11|         18500|\n",
      "|   pan|NULL|      NULL|  NULL|         31|                11|         18500|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mean\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = ['Age', 'Experience', 'Salary'],\n",
    "    outputCols = [\"{}_imputed\".format(a) for a in ['Age', 'Experience', 'Salary']]\n",
    ").setStrategy(\"mean\") # median mode mean\n",
    "df_null_pyspark= df;\n",
    "\n",
    "imputer.fit(df_null_pyspark).transform(df_null_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a92e4b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+\n",
      "|  Name| Age|Age_imputed|\n",
      "+------+----+-----------+\n",
      "| Krish|  30|         30|\n",
      "|   Sid|  25|         25|\n",
      "|  Mary|  41|         41|\n",
      "|Mahesh|NULL|         31|\n",
      "|   Sam|  32|         32|\n",
      "|  Miss|  29|         29|\n",
      "|      |NULL|         31|\n",
      "|   pan|NULL|         31|\n",
      "+------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mean\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = ['Age'],\n",
    "    outputCols = [\"{}_imputed\".format(a) for a in ['Age']]\n",
    ").setStrategy(\"mean\") # median mode mean\n",
    "df_null_pyspark = df.drop('Experience','Salary') \n",
    "\n",
    "imputer.fit(df_null_pyspark).transform(df_null_pyspark).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80c4090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean as _mean, stddev as _stddev, col\n",
    "\n",
    "df_stats = df.select(\n",
    "    _mean(col('Age')).alias('mean'),\n",
    "    _stddev(col('Age')).alias('std')\n",
    ").collect()\n",
    "\n",
    "mean = df_stats[0]['mean']\n",
    "std = df_stats[0]['std']\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0a93a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|  Name| Age|\n",
      "+------+----+\n",
      "| Krish|  30|\n",
      "|   Sid|  25|\n",
      "|  Mary|  41|\n",
      "|Mahesh|NULL|\n",
      "|   Sam|  32|\n",
      "+------+----+\n",
      "\n",
      "+----+---+----------+------+\n",
      "|Name|Age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|Mary| 41|        16| 75000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter\n",
    "df.filter(\"Salary > 2000\").select([\"Name\",\"Age\"]).show()\n",
    "df\n",
    "\n",
    "df.filter((df['Salary'] > 10000) & (df['Age'] > 40)).show()\n",
    "#& and\n",
    "# | or\n",
    "#~ not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4858b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name| Departments|salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#Groupby and Aggregation\n",
    "\n",
    "path = ['C:/Gayaz/python/PySpark/test3.csv']\n",
    " \n",
    "df = spark.read.csv(path, sep=',', #sep='\\t' tab\n",
    "                       inferSchema=True, header=True)  #inferSchema=true if this not there all feilds are strings\n",
    "spark.read.option('header','true') \n",
    "df.show();\n",
    "print(type(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140b3721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|sum(salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|      35000|\n",
      "|    Sunny|      12000|\n",
      "|    Krish|      19000|\n",
      "|   Mahesh|       7000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Name').sum().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb59c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|max(salary)|\n",
      "+---------+-----------+\n",
      "|Sudhanshu|      20000|\n",
      "|    Sunny|      10000|\n",
      "|    Krish|      10000|\n",
      "|   Mahesh|       4000|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Name').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714bc9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      15000|\n",
      "|    Big Data|      15000|\n",
      "|Data Science|      43000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Departments').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "126b1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|avg(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|     7500.0|\n",
      "|    Big Data|     3750.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Departments').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87070f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|    Big Data|    4|\n",
      "|Data Science|    4|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Departments').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b034b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|      73000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30894ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06337c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f4fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1b408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b266580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3a037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0330405b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7cac0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f69b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
